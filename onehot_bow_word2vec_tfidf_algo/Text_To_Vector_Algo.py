# -*- coding: utf-8 -*-
"""code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VHpkLK1s-0yklGypGs89pwuSp4fPUvSS
"""

### text to num methods in NLP


# 1. one hot encoding
# 2. back of word
# 3. word2vec
# 4. TFIDF

###1 onehot encdoing

from sklearn.preprocessing import OneHotEncoder
from sklearn.feature_extraction.text import CountVectorizer

corpus = ['this is the first document', 'this document is the second document']

vectorizer = CountVectorizer()
vectorizer.fit(corpus)
X = vectorizer.transform(corpus)

enc = OneHotEncoder(handle_unknown='ignore')
encoded_data = enc.fit_transform(X.toarray()).toarray()
print(encoded_data)

###2 back of word algorithms


from sklearn.feature_extraction.text import CountVectorizer

corpus = ['this is the first document', 'this document is the second document']
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(corpus)
print(X.toarray())

###3 word2vec algorithms

import gensim.downloader as api
from gensim.models import Word2Vec
import nltk
nltk.download('punkt')

# Download pre-trained Word2Vec model (if you don't have one)
# model = api.load("glove-twitter-25")  # Or any other pre-trained model

# Example using a simple corpus to train a model (for demonstration):
sentences = [['this', 'is', 'the', 'first', 'sentence'], ['this', 'is', 'the', 'second', 'sentence']]
model = Word2Vec(sentences, min_count=1) # min_count=1 considers all words

print(model.wv['this']) # Get the vector for the word "this"

####4 TFIDF vectorization techniques


from sklearn.feature_extraction.text import TfidfVectorizer

corpus = ['this is the first document', 'this document is the second document']
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(corpus)
print(X.toarray())

